{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Guided Project: Building a spam filter using the Naive Bayes Theorem\n",
    "The goad of the project is to build a spam filder using the multinomail Naive Bayes algorithm. \n",
    "\n",
    "The naive Bayes learn from emails the human has already classified as spam. It can be sum up as \n",
    "-1- learn how human classify messages\n",
    "-2- use this knowledge to compute / estimate some proba (spam and non-spam)\n",
    "-3- apply these generated rules to new messages\n",
    "\n",
    "the data we gonna use as input to build the spam fuild is a datasset of 5572 sms that are already labeled by a human. :\n",
    "- dataset from Tiago A. Almeida and José María Gómez Hidalgo\n",
    "- link :https://archive.ics.uci.edu/ml/datasets/sms+spam+collection\n",
    "- the method to aggregate the data http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/#composition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the dataset\n",
    "Let's get familiar with the dataset we gonna use the libray Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms=pd.read_csv('SMSSpamCollection',sep='\\t',header=None,names=['Label','SMS'])\n",
    "#sms.name = 'All dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.865937\n",
       "spam    0.134063\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms['Label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we see that SMS were classified either as ham or spam :)\n",
    "- 4825 non_spam messages\n",
    "- 747spams\n",
    "so we can already compute some probabilities !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ratio_spam_no_spam(df):\n",
    "    n_non_spam= df['Label'].value_counts()[0]\n",
    "    n_spam= df['Label'].value_counts()[1]\n",
    "    total_sms= df['Label'].count()\n",
    "\n",
    "    p_non_spam = n_non_spam / total_sms\n",
    "    p_spam = n_spam / total_sms\n",
    "\n",
    "    return print(\"{0:.2f}% of the {1} is spam and {2:.2f}% is non_spam\".format(p_spam*100,df.name,p_non_spam*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ratio_spam_no_spam(sms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting test / training set \n",
    "In order to validate the rules we gonna create form these messages we gonna spit the dataset between\n",
    "- a training set : will be use to generate the rules\n",
    "- a test set : will be used to test the rules we generated\n",
    "\n",
    "We gonna split 4/5 for the training and 1/5 for the test set meaning \n",
    "- 4458 messages for training set \n",
    "- 1114 messages for testing \n",
    "1114 + 4458 = 5572 :D\n",
    "\n",
    "inthe next blocs we gonna create the training set and use the .drop method to attriute the remaining sns to the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the training set \n",
    "training_set=sms.sample(frac=0.8,random_state=1)\n",
    "training_set.name='Training Set'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>ham</td>\n",
       "      <td>U say leh... Of course nothing happen lar. Not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4527</th>\n",
       "      <td>spam</td>\n",
       "      <td>I want some cock! My hubby's away, I need a re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3201</th>\n",
       "      <td>ham</td>\n",
       "      <td>Just curious because my cuz asked what I was u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                                SMS\n",
       "224    ham  U say leh... Of course nothing happen lar. Not...\n",
       "4527  spam  I want some cock! My hubby's away, I need a re...\n",
       "3201   ham  Just curious because my cuz asked what I was u..."
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.sample(3,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label    4458\n",
       "SMS      4458\n",
       "dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all seeems fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating test set\n",
    "test_set= sms.drop(training_set.index)\n",
    "test_set.name='Test Set'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>spam</td>\n",
       "      <td>XXXMobileMovieClub: To use your credit, click ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ham</td>\n",
       "      <td>Fine if thats the way u feel. Thats the way ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ham</td>\n",
       "      <td>Is that seriously how you spell his name?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5546</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ic. There are a lotta childporn cars then.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5549</th>\n",
       "      <td>ham</td>\n",
       "      <td>You know, wot people wear. T shirts, jumpers, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5552</th>\n",
       "      <td>ham</td>\n",
       "      <td>Have a safe trip to Nigeria. Wish you happines...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5555</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yeh. Indians was nice. Tho it did kane me off ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5563</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ard 6 like dat lor.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1114 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                                SMS\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "14     ham                I HAVE A DATE ON SUNDAY WITH WILL!!\n",
       "15    spam  XXXMobileMovieClub: To use your credit, click ...\n",
       "18     ham  Fine if thats the way u feel. Thats the way ...\n",
       "20     ham          Is that seriously how you spell his name?\n",
       "...    ...                                                ...\n",
       "5546   ham         Ic. There are a lotta childporn cars then.\n",
       "5549   ham  You know, wot people wear. T shirts, jumpers, ...\n",
       "5552   ham  Have a safe trip to Nigeria. Wish you happines...\n",
       "5555   ham  Yeh. Indians was nice. Tho it did kane me off ...\n",
       "5563   ham                                Ard 6 like dat lor.\n",
       "\n",
       "[1114 rows x 2 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test if one index of the training set inthe the test test \n",
    "#test_set.loc[4527] # index belonging to the training test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we get an error message all fine. \n",
    "\n",
    "let's check the ration spam / non spam is both sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ratio_spam_no_spam(sms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ratio_spam_no_spam(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ratio_spam_no_spam(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ratios between the different data sets are similar we can continue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Letter case and punctuation\n",
    "in order to create a db of vocabulary we gonna remove all punctuation and lowercase all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>ham</td>\n",
       "      <td>yep  by the pretty sculpture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4028</th>\n",
       "      <td>ham</td>\n",
       "      <td>yes  princess  are you going to make me moan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>ham</td>\n",
       "      <td>welp apparently he retired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4642</th>\n",
       "      <td>ham</td>\n",
       "      <td>havent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4674</th>\n",
       "      <td>ham</td>\n",
       "      <td>i forgot 2 ask ü all smth   there s a card on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                                SMS\n",
       "1078   ham                       yep  by the pretty sculpture\n",
       "4028   ham      yes  princess  are you going to make me moan \n",
       "958    ham                         welp apparently he retired\n",
       "4642   ham                                            havent \n",
       "4674   ham  i forgot 2 ask ü all smth   there s a card on ..."
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fixing the SMS columns\n",
    "training_set['SMS']=training_set['SMS'].str.replace('\\W', ' ') #regex for any characters which is not A-Z a-z 0-9\n",
    "training_set['SMS']=training_set['SMS'].str.lower() #to have all in lowercase\n",
    "training_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of the vocabulary\n",
    "- we gonna loop through all the sms and\n",
    "- each sms split by words\n",
    "- each words add to list \n",
    "- list transformed to set to remove dupli then back to a list "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  !!!!! \n",
    "because of the approach in counting the words, the index of the training and test sets need to be reset, when I will do the approach with the fingerprinting it won't necessary. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reset index\n",
    "training_set= training_set.reset_index(drop=True)\n",
    "test_set = test_set.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set['SMS']=training_set['SMS'].str.split()\n",
    "vocabulary = [] #the list\n",
    "for text in training_set['SMS']: #loop through sms\n",
    "    for word in text:\n",
    "        vocabulary.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72427\n",
      "7783\n"
     ]
    }
   ],
   "source": [
    "#how big is our vocabulary\n",
    "print(len(vocabulary))#list to set to remove duplicate\n",
    "vocabulary = list(set(vocabulary))\n",
    "print(len(vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We effectively removed a lot duplicated words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final training set\n",
    "now we have our vocabulary, we gonna count \n",
    "transform each sms to a fingerprint as counts of words appear from our vocabulary databases\n",
    "\n",
    "we first create a \n",
    "see block down for an exemple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nword_counts_per_sms_exemple = {'secret': [2,1,1],\\n                       'prize': [2,0,1],\\n                       'claim': [1,0,1],\\n                       'now': [1,0,1],\\n                       'coming': [0,1,0],\\n                       'to': [0,1,0],\\n                       'my': [0,1,0],\\n                       'party': [0,1,0],\\n                       'winner': [0,0,1]\\n                      }\\nword_counts_exemple = pd.DataFrame(word_counts_per_sms_exemple)\\nword_counts_exemple.head()\\n\""
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#exemple\n",
    "'''\n",
    "\n",
    "word_counts_per_sms_exemple = {'secret': [2,1,1],\n",
    "                       'prize': [2,0,1],\n",
    "                       'claim': [1,0,1],\n",
    "                       'now': [1,0,1],\n",
    "                       'coming': [0,1,0],\n",
    "                       'to': [0,1,0],\n",
    "                       'my': [0,1,0],\n",
    "                       'party': [0,1,0],\n",
    "                       'winner': [0,0,1]\n",
    "                      }\n",
    "word_counts_exemple = pd.DataFrame(word_counts_per_sms_exemple)\n",
    "word_counts_exemple.head()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initation the dictionnary with each value is a array of the size of the size of the training set\n",
    "word_counts_per_sms = {unique_word: [0] * len(training_set['SMS']) for unique_word in vocabulary}\n",
    "for index, text in enumerate(training_set['SMS']):\n",
    "    for word in text:\n",
    "        word_counts_per_sms[word][index] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>waves</th>\n",
       "      <th>bac</th>\n",
       "      <th>congrats</th>\n",
       "      <th>3100</th>\n",
       "      <th>delhi</th>\n",
       "      <th>dessert</th>\n",
       "      <th>toppoly</th>\n",
       "      <th>hurting</th>\n",
       "      <th>crave</th>\n",
       "      <th>kid</th>\n",
       "      <th>...</th>\n",
       "      <th>prey</th>\n",
       "      <th>dine</th>\n",
       "      <th>totes</th>\n",
       "      <th>proverb</th>\n",
       "      <th>place</th>\n",
       "      <th>ph</th>\n",
       "      <th>collapsed</th>\n",
       "      <th>welp</th>\n",
       "      <th>hand</th>\n",
       "      <th>yahoo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7783 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   waves  bac  congrats  3100  delhi  dessert  toppoly  hurting  crave  kid  \\\n",
       "0      0    0         0     0      0        0        0        0      0    0   \n",
       "1      0    0         0     0      0        0        0        0      0    0   \n",
       "2      0    0         0     0      0        0        0        0      0    0   \n",
       "3      0    0         0     0      0        0        0        0      0    0   \n",
       "4      0    0         0     0      0        0        0        0      0    0   \n",
       "\n",
       "   ...  prey  dine  totes  proverb  place  ph  collapsed  welp  hand  yahoo  \n",
       "0  ...     0     0      0        0      0   0          0     0     0      0  \n",
       "1  ...     0     0      0        0      0   0          0     0     0      0  \n",
       "2  ...     0     0      0        0      0   0          0     1     0      0  \n",
       "3  ...     0     0      0        0      0   0          0     0     0      0  \n",
       "4  ...     0     0      0        0      0   0          0     0     0      0  \n",
       "\n",
       "[5 rows x 7783 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dictionnary to DataFrame\n",
    "word_counts = pd.DataFrame(word_counts_per_sms)\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>waves</th>\n",
       "      <th>bac</th>\n",
       "      <th>congrats</th>\n",
       "      <th>3100</th>\n",
       "      <th>delhi</th>\n",
       "      <th>dessert</th>\n",
       "      <th>toppoly</th>\n",
       "      <th>hurting</th>\n",
       "      <th>...</th>\n",
       "      <th>prey</th>\n",
       "      <th>dine</th>\n",
       "      <th>totes</th>\n",
       "      <th>proverb</th>\n",
       "      <th>place</th>\n",
       "      <th>ph</th>\n",
       "      <th>collapsed</th>\n",
       "      <th>welp</th>\n",
       "      <th>hand</th>\n",
       "      <th>yahoo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yep, by, the, pretty, sculpture]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yes, princess, are, you, going, to, make, me,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>[welp, apparently, he, retired]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[havent]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[i, forgot, 2, ask, ü, all, smth, there, s, a,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS  waves  bac  \\\n",
       "0   ham                  [yep, by, the, pretty, sculpture]      0    0   \n",
       "1   ham  [yes, princess, are, you, going, to, make, me,...      0    0   \n",
       "2   ham                    [welp, apparently, he, retired]      0    0   \n",
       "3   ham                                           [havent]      0    0   \n",
       "4   ham  [i, forgot, 2, ask, ü, all, smth, there, s, a,...      0    0   \n",
       "\n",
       "   congrats  3100  delhi  dessert  toppoly  hurting  ...  prey  dine  totes  \\\n",
       "0         0     0      0        0        0        0  ...     0     0      0   \n",
       "1         0     0      0        0        0        0  ...     0     0      0   \n",
       "2         0     0      0        0        0        0  ...     0     0      0   \n",
       "3         0     0      0        0        0        0  ...     0     0      0   \n",
       "4         0     0      0        0        0        0  ...     0     0      0   \n",
       "\n",
       "   proverb  place  ph  collapsed  welp  hand  yahoo  \n",
       "0        0      0   0          0     0     0      0  \n",
       "1        0      0   0          0     0     0      0  \n",
       "2        0      0   0          0     1     0      0  \n",
       "3        0      0   0          0     0     0      0  \n",
       "4        0      0   0          0     0     0      0  \n",
       "\n",
       "[5 rows x 7785 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set_clean=pd.concat([training_set,word_counts],axis='columns')\n",
    "training_set_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now all the info needed to start computing some proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the constants\n",
    "Some of the terms in the four equations above will have the same value for every new message. As a start, let's first calculate:\n",
    "\n",
    "- p_spam and p_ham\n",
    "- n_Spam, n_Ham, n_vocabulary\n",
    "- Recall that:\n",
    "\n",
    "    - n_spam is equal to the number of words in all the spam messages — it's not equal to the number of spam messages, and it's not equal to the total number of unique words in spam messages.\n",
    "    - n_ham is equal to the number of words in all the non-spam messages — it's not equal to the number of non-spam messages, and it's not equal to the total number of unique words in non-spam messages.\n",
    "    - We'll also use Laplace smoothing and set . If you need help at any point, don't forget that you can find the solutions notebook here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of words in the spam messages \n",
    "spam_training_set = training_set_clean[training_set_clean['Label']=='spam']\n",
    "ham_training_set=training_set_clean[training_set_clean['Label']=='ham']\n",
    "\n",
    "# p(spam) and P(ham)\n",
    "p_spam = len(spam_training_set) / len(training_set_clean)\n",
    "p_ham = len(ham_training_set) / len(training_set_clean)\n",
    "\n",
    "#N_spam\n",
    "n_spam = spam_training_set.apply(len).sum()\n",
    "#N Ham\n",
    "n_ham = ham_training_set.apply(len).sum()\n",
    "\n",
    "#N_vocabulary\n",
    "n_vocabulary= len(vocabulary)\n",
    "\n",
    "#Laplace smoothing \n",
    "alpha=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculation parameters\n",
    "\n",
    "- in order to compute P(wi | spam) et P(wi|ham) on va creer 2 dictionnairies, one for spam and one for ham, the dictionnary with the vocabulary databse we create above \n",
    "- then we loop through the spammessages and compute the proba P(wi|spam) with \n",
    "        P(wi|spam) = ( N(wi|spam) + alpha) / (Nspam + N_vocabulary * alpha)\n",
    "- same with ham messages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up the dictionnaries:\n",
    "vocabulary_spam={}\n",
    "vocabulary_ham={}\n",
    "for word in vocabulary:\n",
    "    vocabulary_spam[word]=0\n",
    "    vocabulary_ham[word]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute proba wi|spam\n",
    "for key in vocabulary_spam:\n",
    "    vocabulary_spam[key]=(spam_training_set[key].sum() + alpha) / ( n_spam + n_vocabulary * alpha)\n",
    "    \n",
    "#proba wi|ham\n",
    "for key in vocabulary_ham:\n",
    "     vocabulary_ham[key]=(ham_training_set[key].sum() + alpha) / ( n_ham + n_vocabulary * alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1373079281514018e-07\n",
      "1.3314554042493331e-07\n"
     ]
    }
   ],
   "source": [
    "print(vocabulary_spam['welp'])\n",
    "print(vocabulary_ham['welp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " better to call the dictionnaries parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_spam= vocabulary_spam\n",
    "parameters_ham = vocabulary_ham"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifiying a new message\n",
    "now that we have computed the proba of each words if a spam or an ham message, if we take a new message we can then compute for this message:\n",
    "- P(Spam | w1,w2...wn) and - P(Ham | w1,w2...wn) meaning the proba the message is either a spam or a ham while knowing its content (and this based on the rules derived from the training set).\n",
    "\n",
    "we gonna right all that as a function that  :\n",
    "- Takes in as input a new message (w1, w2, ..., wn)\n",
    "- Calculates P(Spam|w1, w2, ..., wn) and P(Ham|w1, w2, ..., wn)\n",
    "- Compares the values of P(Spam|w1, w2, ..., wn) and P(Ham|w1, w2, ..., wn), and:\n",
    "- If P(Ham|w1, w2, ..., wn) > P(Spam|w1, w2, ..., wn), then the message is classified as ham.\n",
    "- If P(Ham|w1, w2, ..., wn) < P(Spam|w1, w2, ..., wn), then the message is classified as spam.\n",
    "- If P(Ham|w1, w2, ..., wn) = P(Spam|w1, w2, ..., wn), then the algorithm may request human help.\n",
    "\n",
    "=> for that we gonna use the test set :D "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def classify(message):\n",
    "\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower().split()\n",
    "        \n",
    "#compute the p_spam_given message by looping through the message and updating the probabily\n",
    "    p_spam_given_message = p_spam \n",
    "    p_ham_given_message = p_ham\n",
    "    \n",
    "    for word in message:\n",
    "        if word in parameters_spam:\n",
    "            p_spam_given_message = p_spam_given_message * parameters_spam[word]\n",
    "\n",
    "        if word in parameters_ham:\n",
    "            p_ham_given_message = p_ham_given_message * parameters_ham[word]\n",
    "\n",
    "    print('P(Spam|message):', p_spam_given_message)\n",
    "    print('P(Ham|message):', p_ham_given_message)\n",
    "\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        print('Label: Ham')\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        print('Label: Spam')\n",
    "    else:\n",
    "        print('Equal proabilities, have a human classify this!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test cases of our function\n",
    "- 'WINNER!! This is the secret code to unlock the money: C3421.'\n",
    "- \"Sounds good, Tom, then see u there\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 2.2361181244033363e-46\n",
      "P(Ham|message): 2.0179400655053473e-51\n",
      "Label: Spam\n"
     ]
    }
   ],
   "source": [
    "classify('WINNER!! This is the secret code to unlock the money: C3421.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 3.0332159335259197e-25\n",
      "P(Ham|message): 2.6170449987544287e-22\n",
      "Label: Ham\n"
     ]
    }
   ],
   "source": [
    "classify(\" dinner at my place\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 1.676839627472796e-41\n",
      "P(Ham|message): 8.202208476864172e-40\n",
      "Label: Ham\n"
     ]
    }
   ],
   "source": [
    "classify(\"Sounds good, Tom, then see u there\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy of our new spam filter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_test_set(message):\n",
    "\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "\n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "\n",
    "    for word in message:\n",
    "        if word in parameters_spam:\n",
    "            p_spam_given_message *= parameters_spam[word]\n",
    "\n",
    "        if word in parameters_ham:\n",
    "            p_ham_given_message *= parameters_ham[word]\n",
    "\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        return 'ham'\n",
    "    elif p_spam_given_message > p_ham_given_message:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'needs human classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set['predicted'] = test_set['SMS'].apply(classify_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>XXXMobileMovieClub: To use your credit, click ...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Fine if thats the way u feel. Thats the way ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Is that seriously how you spell his name?</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS predicted\n",
       "0  spam  Free entry in 2 a wkly comp to win FA Cup fina...      spam\n",
       "1   ham                I HAVE A DATE ON SUNDAY WITH WILL!!      spam\n",
       "2  spam  XXXMobileMovieClub: To use your credit, click ...      spam\n",
       "3   ham  Fine if thats the way u feel. Thats the way ...       ham\n",
       "4   ham          Is that seriously how you spell his name?       ham"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 999\n",
      "Incorrect: 115\n",
      "Accuracy: 0.8967684021543986\n"
     ]
    }
   ],
   "source": [
    "#measure accurary\n",
    "correct=0\n",
    "total = test_set.shape[0]\n",
    "    \n",
    "for row in test_set.iterrows():\n",
    "    row = row[1]\n",
    "    if row['Label'] == row['predicted']:\n",
    "        correct += 1\n",
    "        \n",
    "print('Correct:', correct)\n",
    "print('Incorrect:', total - correct)\n",
    "print('Accuracy:', correct/total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "We created a spam filer who management to sorted out correctly almost 90% of all emails of the test set. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going further\n",
    "- Isolate the 115 messages that were classified incorrectly and try to figure out why the algorithm reached the wrong conclusions.\n",
    "- Make the filtering process more complex by making the algorithm sensitive to letter case.\n",
    "- based on the énoncé, we should had like 98% accurary, we should check why we have less. \n",
    "- Get the project portfolio-ready by using a few tips from our style guide for data science projects.\n",
    "\n",
    "solution:https://github.com/dataquestio/solutions/blob/master/Mission433Solutions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
